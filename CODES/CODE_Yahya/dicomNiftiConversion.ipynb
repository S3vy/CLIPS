{
  "metadata": {
    "kernelspec": {
      "name": ""
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# DicomNiftiConversion.py\nDue to some difficulties reading the files in the database, i had to make some changes on the module that reads the data \"DicomNiftiConversion.py.\nThe difficulties met are : \n- SimpleITK does not read philips PET files correctly\n- When the manufacturer=='Philips' and 'Units'!=BQML : the suv factor cannot be calculated, it can be retreived at a specific tag.\n- How to locate the corrected files in the data base?\n- How to locate which corrected Series to use?\n- Slice Location : some dicom series (philips) have no slice location tag\n- Rescale : rescale slope/intercept give wrong suv values\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Issue 1 : SimpleITK does not read philips PET files correctly : \n### Solution : \nUse of the module dicom2nifti to convert PET series into nifti files, then extracting data with nibabel to multiply by the suv_factor.\nNote that nibabel and sitk extract the data with a subtle difference, the image has to be flipped following the 1st dimension to be the way it is supposed to. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import dicom2nifti\nimport dicom2nifti.settings as settings\nimport nibabel as nib\n\ndef convert_dicom_to_nifti(dicom_folder,namae):\n    # Convert the DICOM folder to NIfTI\n    settings. disable_validate_slice_increment() #ignore slice increment discrepancies \n    dicom2nifti.dicom_series_to_nifti(dicom_folder, namae, reorient_nifti=True)\n\nconvert_dicom_to_nifti(seriesDir,'temp.nii')\nimage_float = nib.load('temp.nii').get_fdata()\nimage_float = image_float*suv_factor\nimage_float= np.flip(image_float,1) \n#This mirrors dimension 1 of the image, this way the data is in the same format as sitk extracted data and \n#the model gets data the way it was trained to\nsuv_img = nib.Nifti1Image(image_float, nib.load('temp.nii').affine, nib.load('temp.nii').header)\nnib.save(suv_img, os.path.join(savePath, f'{traits[\"Patient ID\"]}_{traits[\"Modality\"]}_{traits[\"Study Date\"]}.nii.gz'))\nos.remove('temp.nii')\nreturn os.path.join(savePath, f'{traits[\"Patient ID\"]}_{traits[\"Modality\"]}_{traits[\"Study Date\"]}.nii.gz')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Issue 2 : When the manufacturer=='Philips' and 'Units'!=BQML : \nthe suv factor cannot be calculated, it can be retreived at a specific tag.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def bqml_to_suv(dcm_file: pydicom.FileDataset) -> float:\n    '''\n    Calculates the conversion factor from Bq/mL to SUV bw [g/mL] using \n    the dicom header information in one of the images from a dicom series\n    '''\n    # TODO: You can access these attributes in a more user friendly way rather\n    # than using the codes...change this at some point\n    manufacturer = dcm_file[0x00080070].value.lower()\n    units = dcm_file[0x00541001].value.lower()\n    unitIsNotBqml = \"bqml\" not in units\n    if \"philips\" in manufacturer and unitIsNotBqml:\n        print(\"Philips\")\n        suv_factor = float(dcm_file[0x70531000].value)\n    else:\n        #...\n        #Code to calculate the suv for non philips and non bqml series\n    Rescale_Slope= dcm_file[0x0028,0x1053].value\n    Rescale_Intercept=dcm_file[0x0028,0x1052].value\n\n    return (suv_factor, Rescale_Slope, Rescale_Intercept)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Issue 3 and 4: How to locate the corrected files in the data base?\nThe first approach was to look up the 'AttenuationCorrectionMethod' tag : if it is empty, then the series is not corrected, else it is. \nHowever, sometimes, the tag is not empty and has values like 'None' or something signifying that there is no correction. It is hard to interpret these values.\nAnother method would be to look up the 'CorrectedImage' tag. This tag gives and array of elements \nthat indicate which, if any, corrections have been applied to the images in this Series. To identify which PT series is the corrected one we should look for \nthe one with the most corrections. \nSometimes, there are many series with the maximum number of corrections. In this case we give the user the choice.\n\nThe function below makes a dictionnary of all the series with maximum number of corrections. The dictionnary lists the series path and associates it with its description for more visibility.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def list_of_modality_dirs(input_dir):\n    # scan the input dir for directories containing DICOM series\n    # determine which directory corresponds to which modality\n    dir_list = next(os.walk(input_dir))[1]\n    pt_dir_list={}\n    ct_dir_list={}\n    pt_dir=None\n    numberOfCorrections=0\n    for direc in dir_list:\n        file_list = os.listdir(os.path.join(input_dir, direc))\n        for file in file_list:\n            filename = os.path.join(input_dir, direc, file)\n            if filename.endswith(\".dcm\"):\n                ds = pydicom.read_file(filename)\n                Patient_ID = ds.PatientID\n                if ds.Modality == 'PT':\n                    print('Found PET DIR')\n                    if numberOfCorrections<len(ds[0x00280051].value):\n                        numberOfCorrections = len(ds[0x00280051].value) #prend le dossier pet avec le plus de corrections\n                        pt_dir_list={}\n                        pt_dir_list[os.path.join(input_dir,direc)]=ds.SeriesDescription if 'SeriesDescription' in ds else \"\"\n                        break\n                    elif numberOfCorrections==len(ds[0x00280051].value):\n                        pt_dir_list[os.path.join(input_dir,direc)]=ds.SeriesDescription if 'SeriesDescription' in ds else \"\"\n                        break\n                elif ds.Modality == 'CT':\n                    print('Found CT DIR')\n                    ct_dir_list[os.path.join(input_dir,direc)]=ds.SeriesDescription if 'SeriesDescription' in ds else \"\"\n                    break\n                else:\n                    print('Found dir without PET or CT')\n                    break\n    if pt_dir_list=={}:\n        print(\"Could not find PET DIR\")\n        os._exit(0)\n    if ct_dir_list=={}:\n        print(\"Could not find CT DIR\")\n        os._exit(0)\n    else:\n        if len(pt_dir_list)>1:\n            print(f\"Multiple corrected PET files found, please enter the path of the correct file : \", )\n            for element in (pt_dir_list):\n                print(f'{pt_dir_list[element]}',\" \"*(max([len(pt_dir_list[j]) for j in pt_dir_list])-len(pt_dir_list[element])),f'{element}')\n            choice= input(\"Enter path : \")\n            pt_dir=choice\n        else:\n            for element in pt_dir_list:\n                pt_dir=element\n        if len(ct_dir_list)>1:\n            print(f\"Multiple corrected CT files found, please enter the path of the correct file : \", )\n            for element in (ct_dir_list):\n                print(f'{ct_dir_list[element]}',\" \"*(max([len(ct_dir_list[j]) for j in ct_dir_list])-len(ct_dir_list[element])),f'{element}')\n            ct_dir= input(\"Enter path : \")\n        else:\n            for element in ct_dir_list:\n                ct_dir=element\n        modality_dirs = {'PT':pt_dir, 'CT':ct_dir, 'ID': Patient_ID}\n    return modality_dirs",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Issue 5 : Slice Location : some dicom series (philips) have no SliceLocation tag\nMost dicom series have some files that lack the SliceLocation tag, TMTV-NET filters them to avoid abnormalities. Often with philips values, entire\nseries do not have any SliceLocation tag, and we are left with nothing. The user is warned that at least half dicom files have no SliceLocation, and is \ngiven the choice to either take all of the dicom files or to filter them.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def read_slices_from_dir(input_dir):\n    # read and sort .dcm slices from a directory\n    # first, read all dicom files\n    dicom_files = []\n    for root, dirs, files in os.walk(input_dir):\n        for file in files:\n            if file.endswith(\".dcm\"):\n                filename_full = os.path.join(root, file)\n                ds = pydicom.read_file(filename_full)\n                dicom_files.append(ds)\n    # second, only choose files that have 'location' attribure, and sort\n    slices = []\n    skipcount = 0\n    # only include dicom files that represent image slices\n    for f in dicom_files:\n        if skipcount>=len(dicom_files)//2:\n            a=input(\"Warning : More than half files in series have no SliceLocation tag, do you wish to ignore this tag? (y/n)\")\n            if a.lower()=='y':\n                return dicom_files\n            elif a.lower()=='n':\n                slices = []\n                skipcount = 0\n                for f in dicom_files:    \n                    if hasattr(f, 'SliceLocation'):\n                        slices.append(f)\n                    else:\n                        skipcount += 1\n            #print('Skipped {} files'.format(skipcount))\n                slices = sorted(slices,key=lambda s: s.SliceLocation)\n                return slices\n        if hasattr(f, 'SliceLocation'):\n            slices.append(f)\n        else:\n            skipcount += 1\n    #print('Skipped {} files'.format(skipcount))\n    slices = sorted(slices,key=lambda s: s.SliceLocation)\n    return slices\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Issue 6 : rescale slope/intercept give wrong suv values\nWe have observed that when multiplying by rescale slope and adding rescale intercept, suv values are wrong. Without these the suv values are correct.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}